{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading and Cleaning\n",
    "\n",
    "I'll start by loading the dataset, cleaning it (e.g. removing samples with missing values), and ensuring an even distribution of male and female samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1827, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>common_voice_en_41647263.mp3</td>\n",
       "      <td>female_feminine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>common_voice_en_41647505.mp3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>common_voice_en_41764934.mp3</td>\n",
       "      <td>female_feminine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>common_voice_en_41764772.mp3</td>\n",
       "      <td>female_feminine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>common_voice_en_41731634.mp3</td>\n",
       "      <td>non-binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>common_voice_en_41247202.mp3</td>\n",
       "      <td>female_feminine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>common_voice_en_41646915.mp3</td>\n",
       "      <td>female_feminine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>common_voice_en_41735009.mp3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>common_voice_en_41798949.mp3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>common_voice_en_41434940.mp3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              path           gender\n",
       "727   common_voice_en_41647263.mp3  female_feminine\n",
       "779   common_voice_en_41647505.mp3              NaN\n",
       "1405  common_voice_en_41764934.mp3  female_feminine\n",
       "1371  common_voice_en_41764772.mp3  female_feminine\n",
       "986   common_voice_en_41731634.mp3       non-binary\n",
       "9     common_voice_en_41247202.mp3  female_feminine\n",
       "644   common_voice_en_41646915.mp3  female_feminine\n",
       "1108  common_voice_en_41735009.mp3              NaN\n",
       "1630  common_voice_en_41798949.mp3              NaN\n",
       "309   common_voice_en_41434940.mp3              NaN"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('datasets/cv-corpus-20.0-delta-2024-12-06/en/other.csv')\n",
    "print(df.shape)\n",
    "df = df[['path', 'gender']]\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(941, 2)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all samples with no gender\n",
    "df.dropna(subset=['gender'], inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts for each value in 'gender':\n",
      "gender\n",
      "female_feminine       650\n",
      "male_masculine        214\n",
      "non-binary             72\n",
      "do_not_wish_to_say      5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Looking at distributions\n",
    "print(\"Counts for each value in 'gender':\")\n",
    "print(df['gender'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there are far more female samples than male samples. (Note, I will only be considering female and male samples as these are likely to be distinct from each other and so will be easiest for our model to classify.)\n",
    "\n",
    "We will take the lowest count, and use that to limit the other, creating a more even distribution. (Without considering the length of each recording.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214 male samples\n",
      "650 female samples\n",
      "Sample count: 214\n"
     ]
    }
   ],
   "source": [
    "# Use lowest distribution as the limit for number of samples\n",
    "\n",
    "male_sample_count = (df['gender'] == 'male_masculine').sum()\n",
    "print(f\"{male_sample_count} male samples\")\n",
    "\n",
    "female_sample_count = (df['gender'] == 'female_feminine').sum()\n",
    "print(f\"{female_sample_count} female samples\")\n",
    "\n",
    "sample_count = min(male_sample_count, female_sample_count)\n",
    "print(\"Sample count:\", sample_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(214, 2)\n",
      "(214, 2)\n",
      "(428, 2)\n"
     ]
    }
   ],
   "source": [
    "# Ensure same distribution for each category\n",
    "\n",
    "df_male = df[df['gender'] == 'male_masculine'].sample(sample_count)\n",
    "print(df_male.shape)\n",
    "\n",
    "df_female = df[df['gender'] == 'female_feminine'].sample(sample_count)\n",
    "print(df_female.shape)\n",
    "\n",
    "df = pd.concat([df_male, df_female])\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>common_voice_en_41888727.mp3</td>\n",
       "      <td>male_masculine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714</th>\n",
       "      <td>common_voice_en_41888468.mp3</td>\n",
       "      <td>male_masculine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>common_voice_en_41338228.mp3</td>\n",
       "      <td>male_masculine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>common_voice_en_41646768.mp3</td>\n",
       "      <td>female_feminine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>common_voice_en_41731965.mp3</td>\n",
       "      <td>female_feminine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>common_voice_en_41888643.mp3</td>\n",
       "      <td>male_masculine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>common_voice_en_41647350.mp3</td>\n",
       "      <td>female_feminine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>common_voice_en_41447635.mp3</td>\n",
       "      <td>male_masculine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>common_voice_en_41447445.mp3</td>\n",
       "      <td>male_masculine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>common_voice_en_41798941.mp3</td>\n",
       "      <td>female_feminine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              path           gender\n",
       "1824  common_voice_en_41888727.mp3   male_masculine\n",
       "1714  common_voice_en_41888468.mp3   male_masculine\n",
       "136   common_voice_en_41338228.mp3   male_masculine\n",
       "603   common_voice_en_41646768.mp3  female_feminine\n",
       "1031  common_voice_en_41731965.mp3  female_feminine\n",
       "1779  common_voice_en_41888643.mp3   male_masculine\n",
       "751   common_voice_en_41647350.mp3  female_feminine\n",
       "435   common_voice_en_41447635.mp3   male_masculine\n",
       "361   common_voice_en_41447445.mp3   male_masculine\n",
       "1622  common_voice_en_41798941.mp3  female_feminine"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 2\n",
      "Sample: 3\n",
      "Sample: 4\n",
      "Sample: 5\n",
      "Sample: 6\n",
      "Sample: 7\n",
      "Sample: 8\n",
      "Sample: 9\n",
      "Sample: 10\n",
      "Sample: 11\n",
      "Sample: 12\n",
      "Sample: 13\n",
      "Sample: 14\n",
      "Sample: 15\n",
      "Sample: 16\n",
      "Sample: 17\n",
      "Sample: 18\n",
      "Sample: 19\n",
      "Sample: 20\n",
      "Sample: 21\n",
      "Sample: 22\n",
      "Sample: 23\n",
      "Sample: 24\n",
      "Sample: 25\n",
      "Sample: 26\n",
      "Sample: 27\n",
      "Sample: 28\n",
      "Sample: 29\n",
      "Sample: 30\n",
      "Sample: 31\n",
      "Sample: 32\n",
      "Sample: 33\n",
      "Sample: 34\n",
      "Sample: 35\n",
      "Sample: 36\n",
      "Sample: 37\n",
      "Sample: 38\n",
      "Sample: 39\n",
      "Sample: 40\n",
      "Sample: 41\n",
      "Sample: 42\n",
      "Sample: 43\n",
      "Sample: 44\n",
      "Sample: 45\n",
      "Sample: 46\n",
      "Sample: 47\n",
      "Sample: 48\n",
      "Sample: 49\n",
      "Sample: 50\n",
      "Sample: 51\n",
      "Sample: 52\n",
      "Sample: 53\n",
      "Sample: 54\n",
      "Sample: 55\n",
      "Sample: 56\n",
      "Sample: 57\n",
      "Sample: 58\n",
      "Sample: 59\n",
      "Sample: 60\n",
      "Sample: 61\n",
      "Sample: 62\n",
      "Sample: 63\n",
      "Sample: 64\n",
      "Sample: 65\n",
      "Sample: 66\n",
      "Sample: 67\n",
      "Sample: 68\n",
      "Sample: 69\n",
      "Sample: 70\n",
      "Sample: 71\n",
      "Sample: 72\n",
      "Sample: 73\n",
      "Sample: 74\n",
      "Sample: 75\n",
      "Sample: 76\n",
      "Sample: 77\n",
      "Sample: 78\n",
      "Sample: 79\n",
      "Sample: 80\n",
      "Sample: 81\n",
      "Sample: 82\n",
      "Sample: 83\n",
      "Sample: 84\n",
      "Sample: 85\n",
      "Sample: 86\n",
      "Sample: 87\n",
      "Sample: 88\n",
      "Sample: 89\n",
      "Sample: 90\n",
      "Sample: 91\n",
      "Sample: 92\n",
      "Sample: 93\n",
      "Sample: 94\n",
      "Sample: 95\n",
      "Sample: 96\n",
      "Sample: 97\n",
      "Sample: 98\n",
      "Sample: 99\n",
      "Sample: 100\n",
      "Sample: 101\n",
      "Sample: 102\n",
      "Sample: 103\n",
      "Sample: 104\n",
      "Sample: 105\n",
      "Sample: 106\n",
      "Sample: 107\n",
      "Sample: 108\n",
      "Sample: 109\n",
      "Sample: 110\n",
      "Sample: 111\n",
      "Sample: 112\n",
      "Sample: 113\n",
      "Sample: 114\n",
      "Sample: 115\n",
      "Sample: 116\n",
      "Sample: 117\n",
      "Sample: 118\n",
      "Sample: 119\n",
      "Sample: 120\n",
      "Sample: 121\n",
      "Sample: 122\n",
      "Sample: 123\n",
      "Sample: 124\n",
      "Sample: 125\n",
      "Sample: 126\n",
      "Sample: 127\n",
      "Sample: 128\n",
      "Sample: 129\n",
      "Sample: 130\n",
      "Sample: 131\n",
      "Sample: 132\n",
      "Sample: 133\n",
      "Sample: 134\n",
      "Sample: 135\n",
      "Sample: 136\n",
      "Sample: 137\n",
      "Sample: 138\n",
      "Sample: 139\n",
      "Sample: 140\n",
      "Sample: 141\n",
      "Sample: 142\n",
      "Sample: 143\n",
      "Sample: 144\n",
      "Sample: 145\n",
      "Sample: 146\n",
      "Sample: 147\n",
      "Sample: 148\n",
      "Sample: 149\n",
      "Sample: 150\n",
      "Sample: 151\n",
      "Sample: 152\n",
      "Sample: 153\n",
      "Sample: 154\n",
      "Sample: 155\n",
      "Sample: 156\n",
      "Sample: 157\n",
      "Sample: 158\n",
      "Sample: 159\n",
      "Sample: 160\n",
      "Sample: 161\n",
      "Sample: 162\n",
      "Sample: 163\n",
      "Sample: 164\n",
      "Sample: 165\n",
      "Sample: 166\n",
      "Sample: 167\n",
      "Sample: 168\n",
      "Sample: 169\n",
      "Sample: 170\n",
      "Sample: 171\n",
      "Sample: 172\n",
      "Sample: 173\n",
      "Sample: 174\n",
      "Sample: 175\n",
      "Sample: 176\n",
      "Sample: 177\n",
      "Sample: 178\n",
      "Sample: 179\n",
      "Sample: 180\n",
      "Sample: 181\n",
      "Sample: 182\n",
      "Sample: 183\n",
      "Sample: 184\n",
      "Sample: 185\n",
      "Sample: 186\n",
      "Sample: 187\n",
      "Sample: 188\n",
      "Sample: 189\n",
      "Sample: 190\n",
      "Sample: 191\n",
      "Sample: 192\n",
      "Sample: 193\n",
      "Sample: 194\n",
      "Sample: 195\n",
      "Sample: 196\n",
      "Sample: 197\n",
      "Sample: 198\n",
      "Sample: 199\n",
      "Sample: 200\n",
      "Sample: 201\n",
      "Sample: 202\n",
      "Sample: 203\n",
      "Sample: 204\n",
      "Sample: 205\n",
      "Sample: 206\n",
      "Sample: 207\n",
      "Sample: 208\n",
      "Sample: 209\n",
      "Sample: 210\n",
      "Sample: 211\n",
      "Sample: 212\n",
      "Sample: 213\n",
      "Sample: 214\n",
      "Sample: 215\n",
      "Sample: 216\n",
      "Sample: 217\n",
      "Sample: 218\n",
      "Sample: 219\n",
      "Sample: 220\n",
      "Sample: 221\n",
      "Sample: 222\n",
      "Sample: 223\n",
      "Sample: 224\n",
      "Sample: 225\n",
      "Sample: 226\n",
      "Sample: 227\n",
      "Sample: 228\n",
      "Sample: 229\n",
      "Sample: 230\n",
      "Sample: 231\n",
      "Sample: 232\n",
      "Sample: 233\n",
      "Sample: 234\n",
      "Sample: 235\n",
      "Sample: 236\n",
      "Sample: 237\n",
      "Sample: 238\n",
      "Sample: 239\n",
      "Sample: 240\n",
      "Sample: 241\n",
      "Sample: 242\n",
      "Sample: 243\n",
      "Sample: 244\n",
      "Sample: 245\n",
      "Sample: 246\n",
      "Sample: 247\n",
      "Sample: 248\n",
      "Sample: 249\n",
      "Sample: 250\n",
      "Sample: 251\n",
      "Sample: 252\n",
      "Sample: 253\n",
      "Sample: 254\n",
      "Sample: 255\n",
      "Sample: 256\n",
      "Sample: 257\n",
      "Sample: 258\n",
      "Sample: 259\n",
      "Sample: 260\n",
      "Sample: 261\n",
      "Sample: 262\n",
      "Sample: 263\n",
      "Sample: 264\n",
      "Sample: 265\n",
      "Sample: 266\n",
      "Sample: 267\n",
      "Sample: 268\n",
      "Sample: 269\n",
      "Sample: 270\n",
      "Sample: 271\n",
      "Sample: 272\n",
      "Sample: 273\n",
      "Sample: 274\n",
      "Sample: 275\n",
      "Sample: 276\n",
      "Sample: 277\n",
      "Sample: 278\n",
      "Sample: 279\n",
      "Sample: 280\n",
      "Sample: 281\n",
      "Sample: 282\n",
      "Sample: 283\n",
      "Sample: 284\n",
      "Sample: 285\n",
      "Sample: 286\n",
      "Sample: 287\n",
      "Sample: 288\n",
      "Sample: 289\n",
      "Sample: 290\n",
      "Sample: 291\n",
      "Sample: 292\n",
      "Sample: 293\n",
      "Sample: 294\n",
      "Sample: 295\n",
      "Sample: 296\n",
      "Sample: 297\n",
      "Sample: 298\n",
      "Sample: 299\n",
      "Sample: 300\n",
      "Sample: 301\n",
      "Sample: 302\n",
      "Sample: 303\n",
      "Sample: 304\n",
      "Sample: 305\n",
      "Sample: 306\n",
      "Sample: 307\n",
      "Sample: 308\n",
      "Sample: 309\n",
      "Sample: 310\n",
      "Sample: 311\n",
      "Sample: 312\n",
      "Sample: 313\n",
      "Sample: 314\n",
      "Sample: 315\n",
      "Sample: 316\n",
      "Sample: 317\n",
      "Sample: 318\n",
      "Sample: 319\n",
      "Sample: 320\n",
      "Sample: 321\n",
      "Sample: 322\n",
      "Sample: 323\n",
      "Sample: 324\n",
      "Sample: 325\n",
      "Sample: 326\n",
      "Sample: 327\n",
      "Sample: 328\n",
      "Sample: 329\n",
      "Sample: 330\n",
      "Sample: 331\n",
      "Sample: 332\n",
      "Sample: 333\n",
      "Sample: 334\n",
      "Sample: 335\n",
      "Sample: 336\n",
      "Sample: 337\n",
      "Sample: 338\n",
      "Sample: 339\n",
      "Sample: 340\n",
      "Sample: 341\n",
      "Sample: 342\n",
      "Sample: 343\n",
      "Sample: 344\n",
      "Sample: 345\n",
      "Sample: 346\n",
      "Sample: 347\n",
      "Sample: 348\n",
      "Sample: 349\n",
      "Sample: 350\n",
      "Sample: 351\n",
      "Sample: 352\n",
      "Sample: 353\n",
      "Sample: 354\n",
      "Sample: 355\n",
      "Sample: 356\n",
      "Sample: 357\n",
      "Sample: 358\n",
      "Sample: 359\n",
      "Sample: 360\n",
      "Sample: 361\n",
      "Sample: 362\n",
      "Sample: 363\n",
      "Sample: 364\n",
      "Sample: 365\n",
      "Sample: 366\n",
      "Sample: 367\n",
      "Sample: 368\n",
      "Sample: 369\n",
      "Sample: 370\n",
      "Sample: 371\n",
      "Sample: 372\n",
      "Sample: 373\n",
      "Sample: 374\n",
      "Sample: 375\n",
      "Sample: 376\n",
      "Sample: 377\n",
      "Sample: 378\n",
      "Sample: 379\n",
      "Sample: 380\n",
      "Sample: 381\n",
      "Sample: 382\n",
      "Sample: 383\n",
      "Sample: 384\n",
      "Sample: 385\n",
      "Sample: 386\n",
      "Sample: 387\n",
      "Sample: 388\n",
      "Sample: 389\n",
      "Sample: 390\n",
      "Sample: 391\n",
      "Sample: 392\n",
      "Sample: 393\n",
      "Sample: 394\n",
      "Sample: 395\n",
      "Sample: 396\n",
      "Sample: 397\n",
      "Sample: 398\n",
      "Sample: 399\n",
      "Sample: 400\n",
      "Sample: 401\n",
      "Sample: 402\n",
      "Sample: 403\n",
      "Sample: 404\n",
      "Sample: 405\n",
      "Sample: 406\n",
      "Sample: 407\n",
      "Sample: 408\n",
      "Sample: 409\n",
      "Sample: 410\n",
      "Sample: 411\n",
      "Sample: 412\n",
      "Sample: 413\n",
      "Sample: 414\n",
      "Sample: 415\n",
      "Sample: 416\n",
      "Sample: 417\n",
      "Sample: 418\n",
      "Sample: 419\n",
      "Sample: 420\n",
      "Sample: 421\n",
      "Sample: 422\n",
      "Sample: 423\n",
      "Sample: 424\n",
      "Sample: 425\n",
      "Sample: 426\n",
      "Sample: 427\n",
      "Sample: 428\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>gender</th>\n",
       "      <th>mean_spectral_centroid</th>\n",
       "      <th>mean_spectral_bandwidth</th>\n",
       "      <th>mean_spectral_flatness</th>\n",
       "      <th>mean_spectral_rolloff</th>\n",
       "      <th>mean_spectral_contrast</th>\n",
       "      <th>std_spectral_centroid</th>\n",
       "      <th>std_spectral_bandwidth</th>\n",
       "      <th>std_spectral_flatness</th>\n",
       "      <th>...</th>\n",
       "      <th>low_spectral_centroid</th>\n",
       "      <th>low_spectral_bandwidth</th>\n",
       "      <th>low_spectral_flatness</th>\n",
       "      <th>low_spectral_rolloff</th>\n",
       "      <th>low_spectral_contrast</th>\n",
       "      <th>high_spectral_centroid</th>\n",
       "      <th>high_spectral_bandwidth</th>\n",
       "      <th>high_spectral_flatness</th>\n",
       "      <th>high_spectral_rolloff</th>\n",
       "      <th>high_spectral_contrast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>common_voice_en_41730011.mp3</td>\n",
       "      <td>female_feminine</td>\n",
       "      <td>2262.627389</td>\n",
       "      <td>1688.063077</td>\n",
       "      <td>0.035555</td>\n",
       "      <td>4067.891374</td>\n",
       "      <td>25.377517</td>\n",
       "      <td>936.699180</td>\n",
       "      <td>498.735722</td>\n",
       "      <td>0.050806</td>\n",
       "      <td>...</td>\n",
       "      <td>1321.389418</td>\n",
       "      <td>1123.198970</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>2164.0625</td>\n",
       "      <td>12.306321</td>\n",
       "      <td>3520.181507</td>\n",
       "      <td>2397.170993</td>\n",
       "      <td>0.127915</td>\n",
       "      <td>6523.43750</td>\n",
       "      <td>50.995813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>common_voice_en_41888480.mp3</td>\n",
       "      <td>male_masculine</td>\n",
       "      <td>1461.657449</td>\n",
       "      <td>1440.506599</td>\n",
       "      <td>0.022356</td>\n",
       "      <td>2791.633703</td>\n",
       "      <td>25.042415</td>\n",
       "      <td>947.297902</td>\n",
       "      <td>597.313156</td>\n",
       "      <td>0.032204</td>\n",
       "      <td>...</td>\n",
       "      <td>428.704834</td>\n",
       "      <td>648.797042</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>442.1875</td>\n",
       "      <td>13.803415</td>\n",
       "      <td>2581.516268</td>\n",
       "      <td>2149.674837</td>\n",
       "      <td>0.074881</td>\n",
       "      <td>5100.00000</td>\n",
       "      <td>50.282485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>common_voice_en_41888643.mp3</td>\n",
       "      <td>male_masculine</td>\n",
       "      <td>1464.768398</td>\n",
       "      <td>1389.395731</td>\n",
       "      <td>0.024890</td>\n",
       "      <td>2748.252467</td>\n",
       "      <td>24.727168</td>\n",
       "      <td>928.259409</td>\n",
       "      <td>534.447696</td>\n",
       "      <td>0.038236</td>\n",
       "      <td>...</td>\n",
       "      <td>503.066236</td>\n",
       "      <td>771.163865</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>671.8750</td>\n",
       "      <td>13.323797</td>\n",
       "      <td>2700.830408</td>\n",
       "      <td>2126.700830</td>\n",
       "      <td>0.076410</td>\n",
       "      <td>4957.81250</td>\n",
       "      <td>51.372501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>common_voice_en_41888624.mp3</td>\n",
       "      <td>male_masculine</td>\n",
       "      <td>1302.020528</td>\n",
       "      <td>1425.382259</td>\n",
       "      <td>0.021427</td>\n",
       "      <td>2662.185754</td>\n",
       "      <td>24.773648</td>\n",
       "      <td>793.473536</td>\n",
       "      <td>544.230503</td>\n",
       "      <td>0.032450</td>\n",
       "      <td>...</td>\n",
       "      <td>482.027382</td>\n",
       "      <td>809.619646</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>568.7500</td>\n",
       "      <td>13.579615</td>\n",
       "      <td>2244.543923</td>\n",
       "      <td>2131.795777</td>\n",
       "      <td>0.073240</td>\n",
       "      <td>5029.68750</td>\n",
       "      <td>52.013128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>common_voice_en_41646768.mp3</td>\n",
       "      <td>female_feminine</td>\n",
       "      <td>3100.981839</td>\n",
       "      <td>1641.165261</td>\n",
       "      <td>0.225089</td>\n",
       "      <td>4788.692990</td>\n",
       "      <td>23.801538</td>\n",
       "      <td>1894.290589</td>\n",
       "      <td>565.010209</td>\n",
       "      <td>0.383713</td>\n",
       "      <td>...</td>\n",
       "      <td>1206.727693</td>\n",
       "      <td>793.464084</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>1703.1250</td>\n",
       "      <td>13.861297</td>\n",
       "      <td>6394.230238</td>\n",
       "      <td>2227.604056</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>7460.15625</td>\n",
       "      <td>45.726875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>common_voice_en_41645394.mp3</td>\n",
       "      <td>female_feminine</td>\n",
       "      <td>2211.915855</td>\n",
       "      <td>1702.264935</td>\n",
       "      <td>0.041192</td>\n",
       "      <td>4054.787340</td>\n",
       "      <td>25.070557</td>\n",
       "      <td>1019.208118</td>\n",
       "      <td>472.984772</td>\n",
       "      <td>0.057089</td>\n",
       "      <td>...</td>\n",
       "      <td>1165.616117</td>\n",
       "      <td>1164.224065</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>2001.5625</td>\n",
       "      <td>12.748690</td>\n",
       "      <td>3643.072338</td>\n",
       "      <td>2397.958667</td>\n",
       "      <td>0.138391</td>\n",
       "      <td>6470.31250</td>\n",
       "      <td>53.841860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>common_voice_en_41888450.mp3</td>\n",
       "      <td>male_masculine</td>\n",
       "      <td>1447.675428</td>\n",
       "      <td>1381.665695</td>\n",
       "      <td>0.023034</td>\n",
       "      <td>2750.411184</td>\n",
       "      <td>25.023558</td>\n",
       "      <td>849.107613</td>\n",
       "      <td>577.248736</td>\n",
       "      <td>0.034256</td>\n",
       "      <td>...</td>\n",
       "      <td>439.099334</td>\n",
       "      <td>625.629739</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>509.3750</td>\n",
       "      <td>13.459394</td>\n",
       "      <td>2560.383882</td>\n",
       "      <td>2149.748335</td>\n",
       "      <td>0.077855</td>\n",
       "      <td>5012.50000</td>\n",
       "      <td>51.479411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>common_voice_en_41747288.mp3</td>\n",
       "      <td>female_feminine</td>\n",
       "      <td>2197.891366</td>\n",
       "      <td>1712.708196</td>\n",
       "      <td>0.052921</td>\n",
       "      <td>4043.227252</td>\n",
       "      <td>23.471343</td>\n",
       "      <td>1073.865015</td>\n",
       "      <td>420.203680</td>\n",
       "      <td>0.087636</td>\n",
       "      <td>...</td>\n",
       "      <td>1040.330607</td>\n",
       "      <td>1158.112321</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>1765.6250</td>\n",
       "      <td>12.059857</td>\n",
       "      <td>3648.587469</td>\n",
       "      <td>2200.135505</td>\n",
       "      <td>0.134230</td>\n",
       "      <td>6210.93750</td>\n",
       "      <td>49.953772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>common_voice_en_41888587.mp3</td>\n",
       "      <td>male_masculine</td>\n",
       "      <td>1370.915888</td>\n",
       "      <td>1436.610429</td>\n",
       "      <td>0.024319</td>\n",
       "      <td>2702.233356</td>\n",
       "      <td>24.443294</td>\n",
       "      <td>892.199249</td>\n",
       "      <td>541.393067</td>\n",
       "      <td>0.038458</td>\n",
       "      <td>...</td>\n",
       "      <td>495.676742</td>\n",
       "      <td>821.343669</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>617.1875</td>\n",
       "      <td>13.642628</td>\n",
       "      <td>2387.116466</td>\n",
       "      <td>2150.336399</td>\n",
       "      <td>0.078068</td>\n",
       "      <td>5125.00000</td>\n",
       "      <td>51.999503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>common_voice_en_41764879.mp3</td>\n",
       "      <td>female_feminine</td>\n",
       "      <td>2159.654109</td>\n",
       "      <td>1540.059889</td>\n",
       "      <td>0.236802</td>\n",
       "      <td>3930.562034</td>\n",
       "      <td>21.640335</td>\n",
       "      <td>1423.767293</td>\n",
       "      <td>700.286620</td>\n",
       "      <td>0.381444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002454</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>13.030181</td>\n",
       "      <td>4151.183295</td>\n",
       "      <td>2249.448999</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>6703.12500</td>\n",
       "      <td>42.884027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              path           gender  mean_spectral_centroid  \\\n",
       "869   common_voice_en_41730011.mp3  female_feminine             2262.627389   \n",
       "1726  common_voice_en_41888480.mp3   male_masculine             1461.657449   \n",
       "1779  common_voice_en_41888643.mp3   male_masculine             1464.768398   \n",
       "1769  common_voice_en_41888624.mp3   male_masculine             1302.020528   \n",
       "603   common_voice_en_41646768.mp3  female_feminine             3100.981839   \n",
       "512   common_voice_en_41645394.mp3  female_feminine             2211.915855   \n",
       "1701  common_voice_en_41888450.mp3   male_masculine             1447.675428   \n",
       "1269  common_voice_en_41747288.mp3  female_feminine             2197.891366   \n",
       "1753  common_voice_en_41888587.mp3   male_masculine             1370.915888   \n",
       "1396  common_voice_en_41764879.mp3  female_feminine             2159.654109   \n",
       "\n",
       "      mean_spectral_bandwidth  mean_spectral_flatness  mean_spectral_rolloff  \\\n",
       "869               1688.063077                0.035555            4067.891374   \n",
       "1726              1440.506599                0.022356            2791.633703   \n",
       "1779              1389.395731                0.024890            2748.252467   \n",
       "1769              1425.382259                0.021427            2662.185754   \n",
       "603               1641.165261                0.225089            4788.692990   \n",
       "512               1702.264935                0.041192            4054.787340   \n",
       "1701              1381.665695                0.023034            2750.411184   \n",
       "1269              1712.708196                0.052921            4043.227252   \n",
       "1753              1436.610429                0.024319            2702.233356   \n",
       "1396              1540.059889                0.236802            3930.562034   \n",
       "\n",
       "      mean_spectral_contrast  std_spectral_centroid  std_spectral_bandwidth  \\\n",
       "869                25.377517             936.699180              498.735722   \n",
       "1726               25.042415             947.297902              597.313156   \n",
       "1779               24.727168             928.259409              534.447696   \n",
       "1769               24.773648             793.473536              544.230503   \n",
       "603                23.801538            1894.290589              565.010209   \n",
       "512                25.070557            1019.208118              472.984772   \n",
       "1701               25.023558             849.107613              577.248736   \n",
       "1269               23.471343            1073.865015              420.203680   \n",
       "1753               24.443294             892.199249              541.393067   \n",
       "1396               21.640335            1423.767293              700.286620   \n",
       "\n",
       "      std_spectral_flatness  ...  low_spectral_centroid  \\\n",
       "869                0.050806  ...            1321.389418   \n",
       "1726               0.032204  ...             428.704834   \n",
       "1779               0.038236  ...             503.066236   \n",
       "1769               0.032450  ...             482.027382   \n",
       "603                0.383713  ...            1206.727693   \n",
       "512                0.057089  ...            1165.616117   \n",
       "1701               0.034256  ...             439.099334   \n",
       "1269               0.087636  ...            1040.330607   \n",
       "1753               0.038458  ...             495.676742   \n",
       "1396               0.381444  ...               0.000000   \n",
       "\n",
       "      low_spectral_bandwidth  low_spectral_flatness  low_spectral_rolloff  \\\n",
       "869              1123.198970               0.000744             2164.0625   \n",
       "1726              648.797042               0.000018              442.1875   \n",
       "1779              771.163865               0.000056              671.8750   \n",
       "1769              809.619646               0.000040              568.7500   \n",
       "603               793.464084               0.001654             1703.1250   \n",
       "512              1164.224065               0.000705             2001.5625   \n",
       "1701              625.629739               0.000017              509.3750   \n",
       "1269             1158.112321               0.000512             1765.6250   \n",
       "1753              821.343669               0.000065              617.1875   \n",
       "1396                0.000000               0.002454                0.0000   \n",
       "\n",
       "      low_spectral_contrast  high_spectral_centroid  high_spectral_bandwidth  \\\n",
       "869               12.306321             3520.181507              2397.170993   \n",
       "1726              13.803415             2581.516268              2149.674837   \n",
       "1779              13.323797             2700.830408              2126.700830   \n",
       "1769              13.579615             2244.543923              2131.795777   \n",
       "603               13.861297             6394.230238              2227.604056   \n",
       "512               12.748690             3643.072338              2397.958667   \n",
       "1701              13.459394             2560.383882              2149.748335   \n",
       "1269              12.059857             3648.587469              2200.135505   \n",
       "1753              13.642628             2387.116466              2150.336399   \n",
       "1396              13.030181             4151.183295              2249.448999   \n",
       "\n",
       "      high_spectral_flatness  high_spectral_rolloff  high_spectral_contrast  \n",
       "869                 0.127915             6523.43750               50.995813  \n",
       "1726                0.074881             5100.00000               50.282485  \n",
       "1779                0.076410             4957.81250               51.372501  \n",
       "1769                0.073240             5029.68750               52.013128  \n",
       "603                 1.000001             7460.15625               45.726875  \n",
       "512                 0.138391             6470.31250               53.841860  \n",
       "1701                0.077855             5012.50000               51.479411  \n",
       "1269                0.134230             6210.93750               49.953772  \n",
       "1753                0.078068             5125.00000               51.999503  \n",
       "1396                1.000001             6703.12500               42.884027  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "FILE_PATH = \"datasets/cv-corpus-20.0-delta-2024-12-06/en/clips/\"\n",
    "SAMPLE_RATE = 16000\n",
    "LOW_PERCENTILE = 10\n",
    "HIGH_PERCENTILE = 90\n",
    "\n",
    "count = 0\n",
    "\n",
    "# Iterate over rows and access a specific column\n",
    "for index, row in df.iterrows():  # TODO: remove limit\n",
    "    \n",
    "    count += 1\n",
    "    print(\"Sample:\", count)\n",
    "\n",
    "    # Get file name for current sample\n",
    "    file_name = row[\"path\"]\n",
    "\n",
    "    # Load the audio as a waveform `y`\n",
    "    y, sr = librosa.load(FILE_PATH + file_name, sr=SAMPLE_RATE)\n",
    "\n",
    "    # Extract spectral features\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)  # Pitch\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)  # Timbre\n",
    "    spectral_flatness = librosa.feature.spectral_flatness(\n",
    "        y=y\n",
    "    )  # Indicates how noise-like the signal is.\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(\n",
    "        y=y, sr=sr\n",
    "    )  # Frequency below which a certain percentage of the signal's power resides\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(\n",
    "        y=y, sr=sr\n",
    "    )  # Can provide information about vocal quality\n",
    "\n",
    "    # Compute statistics (mean, std, low, high percentiles)\n",
    "    stats = {\n",
    "        \"mean_spectral_centroid\": spectral_centroid.mean(),\n",
    "        \"mean_spectral_bandwidth\": spectral_bandwidth.mean(),\n",
    "        \"mean_spectral_flatness\": spectral_flatness.mean(),\n",
    "        \"mean_spectral_rolloff\": spectral_rolloff.mean(),\n",
    "        \"mean_spectral_contrast\": spectral_contrast.mean(),\n",
    "        \"std_spectral_centroid\": spectral_centroid.std(),\n",
    "        \"std_spectral_bandwidth\": spectral_bandwidth.std(),\n",
    "        \"std_spectral_flatness\": spectral_flatness.std(),\n",
    "        \"std_spectral_rolloff\": spectral_rolloff.std(),\n",
    "        \"std_spectral_contrast\": spectral_contrast.std(),\n",
    "        \"low_spectral_centroid\": np.percentile(spectral_centroid, LOW_PERCENTILE),\n",
    "        \"low_spectral_bandwidth\": np.percentile(spectral_bandwidth, LOW_PERCENTILE),\n",
    "        \"low_spectral_flatness\": np.percentile(spectral_flatness, LOW_PERCENTILE),\n",
    "        \"low_spectral_rolloff\": np.percentile(spectral_rolloff, LOW_PERCENTILE),\n",
    "        \"low_spectral_contrast\": np.percentile(spectral_contrast, LOW_PERCENTILE),\n",
    "        \"high_spectral_centroid\": np.percentile(spectral_centroid, HIGH_PERCENTILE),\n",
    "        \"high_spectral_bandwidth\": np.percentile(spectral_bandwidth, HIGH_PERCENTILE),\n",
    "        \"high_spectral_flatness\": np.percentile(spectral_flatness, HIGH_PERCENTILE),\n",
    "        \"high_spectral_rolloff\": np.percentile(spectral_rolloff, HIGH_PERCENTILE),\n",
    "        \"high_spectral_contrast\": np.percentile(spectral_contrast, HIGH_PERCENTILE),\n",
    "    }\n",
    "\n",
    "    # Add extracted features to the DataFrame\n",
    "    for feature_name, feature_value in stats.items():\n",
    "        df.loc[index, feature_name] = feature_value\n",
    "        \n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis\n",
    "\n",
    "### Evaluating correlation between features and target variable i.e gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Point Biserial Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sorted Point Biserial Correlation Results:\n",
      "mean_spectral_centroid: correlation=0.7127, p-value=1.3833e-67\n",
      "high_spectral_rolloff: correlation=0.7123, p-value=1.7884e-67\n",
      "mean_spectral_rolloff: correlation=0.7003, p-value=2.3913e-64\n",
      "high_spectral_centroid: correlation=0.6443, p-value=1.4623e-51\n",
      "std_spectral_flatness: correlation=0.5516, p-value=1.9243e-35\n",
      "mean_spectral_flatness: correlation=0.5447, p-value=1.9536e-34\n",
      "high_spectral_flatness: correlation=0.5283, p-value=3.8684e-32\n",
      "high_spectral_contrast: correlation=-0.4862, p-value=8.8263e-27\n",
      "std_spectral_centroid: correlation=0.4713, p-value=4.6697e-25\n",
      "high_spectral_bandwidth: correlation=0.4674, p-value=1.2861e-24\n",
      "mean_spectral_bandwidth: correlation=0.4200, p-value=1.0184e-19\n",
      "low_spectral_rolloff: correlation=0.4184, p-value=1.4489e-19\n",
      "mean_spectral_contrast: correlation=-0.3822, p-value=2.4799e-16\n",
      "low_spectral_centroid: correlation=0.3735, p-value=1.2990e-15\n",
      "low_spectral_contrast: correlation=-0.2755, p-value=6.8271e-09\n",
      "std_spectral_contrast: correlation=-0.2423, p-value=3.9076e-07\n",
      "low_spectral_flatness: correlation=0.1551, p-value=1.2886e-03\n",
      "std_spectral_bandwidth: correlation=0.0587, p-value=2.2562e-01\n",
      "std_spectral_rolloff: correlation=-0.0503, p-value=2.9925e-01\n",
      "low_spectral_bandwidth: correlation=0.0433, p-value=3.7146e-01\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy.stats import pointbiserialr\n",
    "\n",
    "# Initialize a list to store correlation results\n",
    "correlation_results = []\n",
    "\n",
    "# Convert gender to binary (e.g., 0 for male, 1 for female)\n",
    "df['gender_binary'] = (df['gender'] == 'female_feminine').astype(int)\n",
    "\n",
    "FEATURES = [\n",
    "    \"mean_spectral_centroid\",\n",
    "    \"mean_spectral_bandwidth\",\n",
    "    \"mean_spectral_flatness\",\n",
    "    \"mean_spectral_rolloff\",\n",
    "    \"mean_spectral_contrast\",\n",
    "    \"std_spectral_centroid\",\n",
    "    \"std_spectral_bandwidth\",\n",
    "    \"std_spectral_flatness\",\n",
    "    \"std_spectral_rolloff\",\n",
    "    \"std_spectral_contrast\",\n",
    "    \"low_spectral_centroid\",\n",
    "    \"low_spectral_bandwidth\",\n",
    "    \"low_spectral_flatness\",\n",
    "    \"low_spectral_rolloff\",\n",
    "    \"low_spectral_contrast\",\n",
    "    \"high_spectral_centroid\",\n",
    "    \"high_spectral_bandwidth\",\n",
    "    \"high_spectral_flatness\",\n",
    "    \"high_spectral_rolloff\",\n",
    "    \"high_spectral_contrast\"\n",
    "]\n",
    "\n",
    "# Calculate Point Biserial Correlation for each feature\n",
    "for feature in FEATURES:\n",
    "    correlation, p_value = pointbiserialr(df[feature].dropna(), df['gender_binary'].dropna())\n",
    "    # Append the result to the list\n",
    "    correlation_results.append({\"feature\": feature, \"correlation\": correlation, \"p_value\": p_value})\n",
    "\n",
    "# Sort results by p-value (ascending)\n",
    "sorted_correlation_results = sorted(correlation_results, key=lambda x: x['p_value'])\n",
    "\n",
    "# Print sorted results\n",
    "print(\"\\nSorted Point Biserial Correlation Results:\")\n",
    "for result in sorted_correlation_results:\n",
    "    print(f\"{result['feature']}: correlation={result['correlation']:.4f}, p-value={result['p_value']:.4e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted T-Test Results:\n",
      "mean_spectral_centroid: t-stat=-20.9684, p-value=1.3833e-67\n",
      "high_spectral_rolloff: t-stat=-20.9436, p-value=1.7884e-67\n",
      "mean_spectral_rolloff: t-stat=-20.2476, p-value=2.3913e-64\n",
      "high_spectral_centroid: t-stat=-17.3876, p-value=1.4623e-51\n",
      "std_spectral_flatness: t-stat=-13.6491, p-value=1.9243e-35\n",
      "mean_spectral_flatness: t-stat=-13.4055, p-value=1.9536e-34\n",
      "high_spectral_flatness: t-stat=-12.8428, p-value=3.8683e-32\n",
      "high_spectral_contrast: t-stat=11.4845, p-value=8.8263e-27\n",
      "std_spectral_centroid: t-stat=-11.0306, p-value=4.6697e-25\n",
      "high_spectral_bandwidth: t-stat=-10.9131, p-value=1.2861e-24\n",
      "mean_spectral_bandwidth: t-stat=-9.5517, p-value=1.0184e-19\n",
      "low_spectral_rolloff: t-stat=-9.5073, p-value=1.4489e-19\n",
      "mean_spectral_contrast: t-stat=8.5356, p-value=2.4799e-16\n",
      "low_spectral_centroid: t-stat=-8.3093, p-value=1.2990e-15\n",
      "low_spectral_contrast: t-stat=5.9148, p-value=6.8271e-09\n",
      "std_spectral_contrast: t-stat=5.1541, p-value=3.9076e-07\n",
      "low_spectral_flatness: t-stat=-3.2401, p-value=1.2886e-03\n",
      "std_spectral_bandwidth: t-stat=-1.2135, p-value=2.2562e-01\n",
      "std_spectral_rolloff: t-stat=1.0393, p-value=2.9925e-01\n",
      "low_spectral_bandwidth: t-stat=-0.8947, p-value=3.7146e-01\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Initialize a list to store t-test results\n",
    "ttest_results = []\n",
    "\n",
    "# Perform t-test for each feature\n",
    "for feature in FEATURES:\n",
    "    male_values = df[df['gender'] == 'male_masculine'][feature].dropna()\n",
    "    female_values = df[df['gender'] == 'female_feminine'][feature].dropna()\n",
    "    \n",
    "    t_stat, p_value = ttest_ind(male_values, female_values)\n",
    "    \n",
    "    # Append the result to the list\n",
    "    ttest_results.append({\"feature\": feature, \"t_stat\": t_stat, \"p_value\": p_value})\n",
    "    \n",
    "# Sort results by p-value (ascending)\n",
    "sorted_ttest_results = sorted(ttest_results, key=lambda x: x['p_value'])\n",
    "\n",
    "# Print sorted results\n",
    "print(\"Sorted T-Test Results:\")\n",
    "for result in sorted_ttest_results:\n",
    "    print(f\"{result['feature']}: t-stat={result['t_stat']:.4f}, p-value={result['p_value']:.4e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Encode gender as binary\n",
    "df['gender_binary'] = (df['gender'] == 'female_feminine').astype(int)\n",
    "\n",
    "# Compute correlations\n",
    "correlation_matrix = df.drop(columns=['path', 'gender']).corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix[['gender_binary']].sort_values(by='gender_binary', ascending=False), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Between Features and Gender')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Findings\n",
    "\n",
    "From these quick tests we can see that there is a high correlation between gender and the following features:\n",
    "- mean_spectral_centroid\n",
    "- high_spectral_rolloff\n",
    "- mean_spectral_rolloff\n",
    "- high_spectral_centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(428, 20)\n",
      "(428,)\n"
     ]
    }
   ],
   "source": [
    "# Split feature and target variables into X and y dataframes\n",
    "\n",
    "X = df[FEATURES]\n",
    "y = df['gender']\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded target values: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Label mapping: {'female_feminine': 0, 'male_masculine': 1}\n"
     ]
    }
   ],
   "source": [
    "# Encode y values which are currently either 'male_masculine' or 'female_feminine'\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the target variable\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Print encoded labels and mapping\n",
    "print(\"Encoded target values:\", y_encoded)\n",
    "print(\"Label mapping:\", dict(zip(label_encoder.classes_, range(len(label_encoder.classes_)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(342, 20) (86, 20) (342,) (86,)\n"
     ]
    }
   ],
   "source": [
    "# Test-train split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "SEED = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Simple Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I've standardized the features. Not all models will use the standardized feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the features (Logistic Regression performs better with standardized data)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[33  2]\n",
      " [ 4 47]]\n",
      "\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "female_feminine       0.89      0.94      0.92        35\n",
      " male_masculine       0.96      0.92      0.94        51\n",
      "\n",
      "       accuracy                           0.93        86\n",
      "      macro avg       0.93      0.93      0.93        86\n",
      "   weighted avg       0.93      0.93      0.93        86\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      "0.9302325581395349\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nAccuracy Score:\")\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best Cross-Validated Accuracy: 0.9591219096334186\n",
      "\n",
      "Confusion Matrix:\n",
      "[[33  2]\n",
      " [ 4 47]]\n",
      "\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "female_feminine       0.89      0.94      0.92        35\n",
      " male_masculine       0.96      0.92      0.94        51\n",
      "\n",
      "       accuracy                           0.93        86\n",
      "      macro avg       0.93      0.93      0.93        86\n",
      "   weighted avg       0.93      0.93      0.93        86\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],  # Regularization type\n",
    "    'solver': ['liblinear', 'saga'],  # Solvers compatible with penalties\n",
    "    'max_iter': [100, 200, 500]  # Convergence iterations\n",
    "}\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# GridSearchCV\n",
    "grid = GridSearchCV(estimator=log_reg, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best parameters and performance\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "print(\"Best Cross-Validated Accuracy:\", grid.best_score_)\n",
    "\n",
    "# Train the best model\n",
    "best_log_reg = grid.best_estimator_\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = best_log_reg.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[35  0]\n",
      " [ 4 47]]\n",
      "\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "female_feminine       0.90      1.00      0.95        35\n",
      " male_masculine       1.00      0.92      0.96        51\n",
      "\n",
      "       accuracy                           0.95        86\n",
      "      macro avg       0.95      0.96      0.95        86\n",
      "   weighted avg       0.96      0.95      0.95        86\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      "0.9534883720930233\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Train the SVM model (default kernel is 'rbf')\n",
    "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nAccuracy Score:\")\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Best Cross-Validated Accuracy: 0.9794543904518329\n",
      "\n",
      "Classification Report (Best Model):\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "female_feminine       0.90      1.00      0.95        35\n",
      " male_masculine       1.00      0.92      0.96        51\n",
      "\n",
      "       accuracy                           0.95        86\n",
      "      macro avg       0.95      0.96      0.95        86\n",
      "   weighted avg       0.96      0.95      0.95        86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.1, 0.01, 0.001],\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid', 'linear']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy')\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best parameters and accuracy\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "print(\"Best Cross-Validated Accuracy:\", grid.best_score_)\n",
    "\n",
    "# Train with best parameters\n",
    "best_svm_model = grid.best_estimator_\n",
    "y_pred_best = best_svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the best model\n",
    "print(\"\\nClassification Report (Best Model):\")\n",
    "print(classification_report(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[32  3]\n",
      " [ 3 48]]\n",
      "\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "female_feminine       0.91      0.91      0.91        35\n",
      " male_masculine       0.94      0.94      0.94        51\n",
      "\n",
      "       accuracy                           0.93        86\n",
      "      macro avg       0.93      0.93      0.93        86\n",
      "   weighted avg       0.93      0.93      0.93        86\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      "0.9302325581395349\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Train Gradient Boosting Classifier\n",
    "gbm_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gbm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = gbm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nAccuracy Score:\")\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Best Cross-Validated Accuracy: 0.9678175618073317\n",
      "\n",
      "Classification Report (Best Model):\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "female_feminine       0.92      0.97      0.94        35\n",
      " male_masculine       0.98      0.94      0.96        51\n",
      "\n",
      "       accuracy                           0.95        86\n",
      "      macro avg       0.95      0.96      0.95        86\n",
      "   weighted avg       0.95      0.95      0.95        86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(GradientBoostingClassifier(random_state=42), param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "print(\"Best Cross-Validated Accuracy:\", grid.best_score_)\n",
    "\n",
    "# Use the best model for predictions\n",
    "best_gbm_model = grid.best_estimator_\n",
    "y_pred = best_gbm_model.predict(X_test)\n",
    "\n",
    "print(\"\\nClassification Report (Best Model):\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest-Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[34  1]\n",
      " [ 3 48]]\n",
      "\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "female_feminine       0.92      0.97      0.94        35\n",
      " male_masculine       0.98      0.94      0.96        51\n",
      "\n",
      "       accuracy                           0.95        86\n",
      "      macro avg       0.95      0.96      0.95        86\n",
      "   weighted avg       0.95      0.95      0.95        86\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      "0.9534883720930233\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Initialize and train the KNN model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)  # Default: Euclidean distance\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = knn_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nAccuracy Score:\")\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'metric': 'euclidean', 'n_neighbors': 5, 'p': 1}\n",
      "Best Cross-Validated Accuracy: 0.9591219096334186\n",
      "\n",
      "Classification Report (Best Model):\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "female_feminine       0.92      0.97      0.94        35\n",
      " male_masculine       0.98      0.94      0.96        51\n",
      "\n",
      "       accuracy                           0.95        86\n",
      "      macro avg       0.95      0.96      0.95        86\n",
      "   weighted avg       0.95      0.95      0.95        86\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\", line 348, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 593, in compute\n",
      "    unique_Y_labels=np.array(unique_Y_labels, dtype=np.intp),\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'female_feminine'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/vchapandrews/Documents/development/speaker-identification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.95618073 0.95618073 0.95912191 0.95912191 0.95319693 0.95319693\n",
      " 0.95609548 0.95609548 0.95025575 0.95025575        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.95618073        nan 0.95912191\n",
      "        nan 0.95319693        nan 0.95609548        nan 0.95025575]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "    'p': [1, 2]  # Minkowski distance power parameter\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best parameters and model\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "print(\"Best Cross-Validated Accuracy:\", grid.best_score_)\n",
    "\n",
    "# Train with the best parameters\n",
    "best_knn_model = grid.best_estimator_\n",
    "y_pred_best = best_knn_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the best model\n",
    "print(\"\\nClassification Report (Best Model):\")\n",
    "print(classification_report(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9534883720930233\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Random Forest: {'bootstrap': True, 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Best Cross-Validated Accuracy for Random Forest: 0.9560528559249788\n",
      "\n",
      "Random Forest Confusion Matrix:\n",
      "[[34  1]\n",
      " [ 3 48]]\n",
      "\n",
      "Random Forest Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "female_feminine       0.92      0.97      0.94        35\n",
      " male_masculine       0.98      0.94      0.96        51\n",
      "\n",
      "       accuracy                           0.95        86\n",
      "      macro avg       0.95      0.96      0.95        86\n",
      "   weighted avg       0.95      0.95      0.95        86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum samples required to be a leaf node\n",
    "    'bootstrap': [True, False]  # Whether to use bootstrap sampling\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_rf = GridSearchCV(estimator=rf_model, param_grid=param_grid_rf, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and model\n",
    "print(\"Best Parameters for Random Forest:\", grid_rf.best_params_)\n",
    "print(\"Best Cross-Validated Accuracy for Random Forest:\", grid_rf.best_score_)\n",
    "\n",
    "# Use the best model\n",
    "best_rf_model = grid_rf.best_estimator_\n",
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nRandom Forest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "print(\"\\nRandom Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.872093023255814\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train_scaled, y_train)\n",
    "y_pred_nb = nb_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With hyperpamater tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Naive Bayes: {'var_smoothing': np.float64(1e-06)}\n",
      "Best Cross-Validated Accuracy for Naive Bayes: 0.923998294970162\n",
      "\n",
      "Naive Bayes Confusion Matrix:\n",
      "[[33  2]\n",
      " [ 5 46]]\n",
      "\n",
      "Naive Bayes Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "female_feminine       0.87      0.94      0.90        35\n",
      " male_masculine       0.96      0.90      0.93        51\n",
      "\n",
      "       accuracy                           0.92        86\n",
      "      macro avg       0.91      0.92      0.92        86\n",
      "   weighted avg       0.92      0.92      0.92        86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid_nb = {\n",
    "    'var_smoothing': np.logspace(-9, 0, 10)  # Test different levels of variance smoothing\n",
    "}\n",
    "\n",
    "# Initialize the Naive Bayes model\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_nb = GridSearchCV(estimator=nb_model, param_grid=param_grid_nb, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_nb.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and model\n",
    "print(\"Best Parameters for Naive Bayes:\", grid_nb.best_params_)\n",
    "print(\"Best Cross-Validated Accuracy for Naive Bayes:\", grid_nb.best_score_)\n",
    "\n",
    "# Use the best model\n",
    "best_nb_model = grid_nb.best_estimator_\n",
    "y_pred_nb = best_nb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nNaive Bayes Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_nb))\n",
    "print(\"\\nNaive Bayes Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "It seems the Support Vector Machine model is the winner, with an accuracy of 97% when tuned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base models\n",
    "estimators = [\n",
    "    ('rf', best_rf_model),\n",
    "    ('svc', best_svm_model),\n",
    "    ('nb', best_nb_model)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model Accuracy: 0.9418604651162791\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_model = VotingClassifier(estimators=estimators, voting='hard')\n",
    "\n",
    "voting_model.fit(X_train_scaled, y_train)\n",
    "y_pred_voting = voting_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Ensemble Model Accuracy:\", accuracy_score(y_test, y_pred_voting))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Accuracy: 0.9418604651162791\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Stacking Classifier\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression()\n",
    ")\n",
    "stacking_model.fit(X_train, y_train)\n",
    "y_pred_stacking = stacking_model.predict(X_test)\n",
    "\n",
    "print(\"Stacking Accuracy:\", accuracy_score(y_test, y_pred_stacking))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "From the tests shown above we can see it is possible to predict the gender of a speaker to a reasonable degree of accuracy using just simple structured data extracted from the recording."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
